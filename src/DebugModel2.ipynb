{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feeb513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vit_pytorch import ViT\n",
    "from graphs import Graph, prims\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from tree_dataset import TreeDataset, show_img\n",
    "import model as m\n",
    "from torch.utils.data import DataLoader\n",
    "from d2lvit import *\n",
    "import copy\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9741ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 1000\n",
      "Identified CUDA device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "torch_test_set = TreeDataset(os.path.join('..', 'data', 'super_variety_1k'), m.resnet_preprocess()) \n",
    "d2l_test_set = TreeDataset(os.path.join('..', 'data', 'super_variety_1k'), preprocess)\n",
    "print(f'Test size: {len(torch_test_set)}')\n",
    "torch_loader = DataLoader(torch_test_set, batch_size=32)\n",
    "d2l_loader = DataLoader(d2l_test_set, batch_size=32)\n",
    "device = m.get_device()\n",
    "config = {'labels_key': 'tree_label'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d6e9eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_31\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0], dtype=torch.int32)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "elem = torch_test_set[31]\n",
    "print(elem['img_name'])\n",
    "print(elem['digit_labels'])\n",
    "print(elem['tree_label'])\n",
    "print(elem['image'].size())\n",
    "show_img(elem['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "531c5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join('..', 'models', 'finetune_super', 'digit-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa67855f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef260798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join('..', 'models', 'd2lvit_3', 'digit-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bf43a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (patch_embedding): PatchEmbedding(\n",
       "    (conv): Conv2d(1, 512, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (blks): Sequential(\n",
       "    (0): ViTBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): MultiHeadAttention(\n",
       "        (attention): DotProductAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "      )\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): ViTMLP(\n",
       "        (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (gelu): GELU(approximate=none)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ViTBlock(\n",
       "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): MultiHeadAttention(\n",
       "        (attention): DotProductAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "      )\n",
       "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): ViTMLP(\n",
       "        (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (gelu): GELU(approximate=none)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf07975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22bbc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.set_torch_vit_dropouts(model, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a38324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e017c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0754 0.0005 0.0001 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss = np.load(os.path.join('..', 'models', 'finetune_3', 'tree_train_loss.npy'))\n",
    "val_acc = np.load(os.path.join('..', 'models', 'finetune_3', 'tree_val_acc.npy'))\n",
    "epochs = np.arange(1, train_loss.shape[0]+1)\n",
    "plt.plot(epochs, train_loss, label='loss')\n",
    "plt.plot(epochs, val_acc, label='acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(' '.join(f'{e:.4f}' for e in train_loss[::10]))\n",
    "print(' '.join(f'{e:.4f}' for e in val_acc[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d743d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
